create sequence addax_log_id_seq;

create sequence etl_job_queue_id_seq;

create sequence etl_jour_id_seq;

create sequence etl_source_id_seq as integer;

create sequence etl_statistic_id_seq;

create sequence group_members_id_seq;

create sequence groups_id_seq;

create sequence notification_id_seq;

create sequence schema_change_log_id_seq;

create sequence tb_addax_statistic_id_seq;

create sequence tb_imp_etl_tid_seq;

create sequence leader_election_id_seq as integer;

create sequence risk_log_id_seq;

create table public.addax_log
(
  id       bigserial
    primary key,
  tid      bigint not null,
  run_at   timestamp,
  run_date date,
  log      text
);

create index idx_tid_run_date
  on public.addax_log (tid, run_at);

create table public.etl_job_queue
(
  id           bigserial
    primary key,
  tid          bigint                                                        not null,
  biz_date     date                                                          not null,
  part_name    varchar(64),
  payload      jsonb,
  priority     integer                  default 100                          not null,
  status       varchar(16)              default 'pending'::character varying not null
    constraint etl_job_queue_status_chk
      check ((status)::text = ANY
             (ARRAY [('pending'::character varying)::text, ('running'::character varying)::text, ('completed'::character varying)::text, ('failed'::character varying)::text, ('cancelled'::character varying)::text])),
  available_at timestamp with time zone default now()                        not null,
  attempts     integer                  default 0                            not null,
  max_attempts integer                  default 3                            not null,
  claimed_by   varchar(128),
  claimed_at   timestamp with time zone,
  lease_until  timestamp with time zone,
  last_error   text,
  created_at   timestamp with time zone default now()                        not null,
  updated_at   timestamp with time zone default now()                        not null
);

create index idx_etl_job_queue_lease
  on public.etl_job_queue (status, lease_until);

create index idx_etl_job_queue_status_available
  on public.etl_job_queue (status, available_at, priority);

create unique index uniq_active_etl_job
  on public.etl_job_queue (tid, biz_date)
  where ((status)::text = ANY (ARRAY [('pending'::character varying)::text, ('running'::character varying)::text]));

create index idx_etl_job_queue_pending_priority_available
  on public.etl_job_queue (priority, available_at, id)
  where ((status)::text = 'pending'::text);

create index idx_etl_job_queue_running_lease_until
  on public.etl_job_queue (lease_until)
  where ((status)::text = 'running'::text);

create table public.etl_source
(
  id              serial
    primary key,
  code            varchar(50)       not null,
  name            varchar(200)      not null,
  url             varchar(500)      not null,
  username        varchar(64),
  pass            varchar(64),
  start_at        time,
  prerequisite    varchar(4000),
  pre_script      varchar(4000),
  remark          varchar(2000),
  enabled         boolean default true,
  max_concurrency integer default 5 not null,
  db_type         varchar(20)
);

comment on table public.etl_source is '采集源表';

comment on column public.etl_source.id is '采集源 ID';

comment on column public.etl_source.code is '采集编号,一般以两个大写字母作为标志';

comment on column public.etl_source.name is '采集源名称';

comment on column public.etl_source.url is '采集源 JDBC 连接串';

comment on column public.etl_source.username is '采集源连接的账号';

comment on column public.etl_source.pass is '采集源连接的密码';

comment on column public.etl_source.start_at is '采集的定时启动时间点，一般只考虑到小时和分钟，秒钟默认为 0';

comment on column public.etl_source.prerequisite is '能否开始采集的先决条件，比如获取采集标志位，或者等待数据不再更新，一般是一段 SQL，然后通过返回值真假进行判断';

comment on column public.etl_source.pre_script is '标志符合条件后的前置脚本';

comment on column public.etl_source.remark is '系统备注信息';

comment on column public.etl_source.enabled is '是否有效';

comment on column public.etl_source.max_concurrency is '采集源允许的最大并发数';

comment on column public.etl_source.db_type is '数据库类型';

create table public.etl_statistic
(
  id           bigint generated by default as identity
    constraint tb_addax_statistic_pkey
      primary key,
  tid          bigint,
  start_at     timestamp,
  end_at       timestamp,
  take_secs    integer,
  total_bytes  bigint,
  byte_speed   integer,
  rec_speed    integer,
  total_recs   bigint,
  total_errors integer,
  biz_date     date,
  constraint etl_statistic_tid_biz_date
    unique (tid, biz_date)
);

comment on table public.etl_statistic is '采集统计表';

comment on column public.etl_statistic.id is '逻辑主键';

comment on column public.etl_statistic.tid is '采集表主键';

comment on column public.etl_statistic.start_at is '采集开始时间';

comment on column public.etl_statistic.end_at is '采集结束时间';

comment on column public.etl_statistic.take_secs is '采集耗时';

comment on column public.etl_statistic.total_bytes is '采集的总字节数';

comment on column public.etl_statistic.byte_speed is '采集速度  字节/秒';

comment on column public.etl_statistic.rec_speed is '采集速度 行/秒';

comment on column public.etl_statistic.total_recs is '采集的总行数';

comment on column public.etl_statistic.total_errors is '采集时发生错误的行数';

comment on column public.etl_statistic.biz_date is '采集业务日期';


create table public.etl_table
(
  id              bigint        default nextval('tb_imp_etl_tid_seq'::regclass) not null
    constraint tb_imp_etl_pkey1
      primary key,
  source_db       varchar(32)                                                   not null,
  source_table    varchar(64)                                                   not null,
  target_db       varchar(50)                                                   not null,
  target_table    varchar(200)                                                  not null,
  part_kind       char          default 'D'::bpchar,
  part_name       varchar(20)   default 'logdate'::character varying,
  filter          varchar(2000) default '1=1'::character varying                not null,
  kind            char          default 'A'::bpchar,
  retry_cnt       integer       default 3,
  start_time      timestamp     default CURRENT_TIMESTAMP,
  end_time        timestamp     default CURRENT_TIMESTAMP,
  max_runtime     integer       default 2000,
  sid             integer                                                       not null
    constraint etl_table_sid_fk
      references public.etl_source,
  duration        integer       default 0                                       not null,
  part_format     varchar(10)   default 'yyyyMMdd'::character varying,
  storage_format  varchar(10)   default 'orc'::character varying                not null,
  compress_format varchar(10)   default 'snappy'::character varying             not null,
  tbl_comment     varchar(500),
  status          char          default 'U'::bpchar                             not null,
  split_pk        varchar(50)   default NULL::character varying,
  auto_pk         boolean       default true                                    not null,
  write_mode varchar(20) default 'overwrite' not null
);

create table if not exists public.etl_target
(
  id               bigserial primary key,
  code             varchar(50)  not null,
  name             varchar(100) not null,
  target_type      varchar(30)  not null,
  connect_config   text,
  writer_template_key varchar(32),
  enabled          boolean default true not null,
  is_default       boolean default false not null,
  remark           varchar(500)
);

create unique index if not exists uk_etl_target_code
  on public.etl_target (code);

comment on table public.etl_table is '采集表信息';

comment on column public.etl_table.id is '表 ID';

comment on column public.etl_table.source_db is '采集源库名或 schema名称或 owner 名称';

comment on column public.etl_table.source_table is '采集源表名';

comment on column public.etl_table.target_db is '目标库名，即提供给 hive 的库名';

comment on column public.etl_table.target_table is '目标表名，即 Hive 的表名';

comment on column public.etl_table.part_kind is '分区类型，D - 按每日分区，如果为空，则表示不分区';

comment on column public.etl_table.part_name is '目标表分区字段名称，如果 dest_part_kind 不为空，则该字段也不能为空';

comment on column public.etl_table.filter is '采集过滤条件，即 where 条件';

comment on column public.etl_table.kind is '采集类型: A - 自动采集(默认值); M - 手工采集; R - 实时采集';

comment on column public.etl_table.retry_cnt is '采集的重试次数，用于采集失败时，可以多次尝试';

comment on column public.etl_table.start_time is '本次采集的开始时间';

comment on column public.etl_table.end_time is '本次采集的结束时间';

comment on column public.etl_table.max_runtime is '采集可只持续的最大时间，避免某些采集因为网络或数据源原因一直无法结束';

comment on column public.etl_table.sid is '采集源 ID，对应 etl_source 表 id';

comment on column public.etl_table.duration is '采集耗时，单位为秒';

comment on column public.etl_table.part_format is '分区字段日期格式';

comment on column public.etl_table.storage_format is '压缩格式，可以是snappy,zlib,lz4,gz,bz2,zstd 等';

comment on column public.etl_table.tbl_comment is '表注释';

comment on column public.etl_table.split_pk is '切分主键';

comment on column public.etl_table.auto_pk is '自动获取切分字段';

comment on column etl_table.write_mode is '覆盖默认，默认为 overwrite，可选为 append,nonConflict';

alter table public.etl_table
  add column if not exists target_id bigint;

do
$$
begin
  if not exists (select 1 from pg_constraint where conname = 'etl_table_target_id_fk') then
    alter table public.etl_table
      add constraint etl_table_target_id_fk
      foreign key (target_id) references public.etl_target (id);
  end if;
end
$$;

create index if not exists idx_etl_table_target_id
  on public.etl_table (target_id);

comment on table public.etl_target is '目标端配置表';
comment on column public.etl_target.id is '目标端主键ID';
comment on column public.etl_target.code is '目标端编码';
comment on column public.etl_target.name is '目标端名称';
comment on column public.etl_target.target_type is '目标端类型（HDFS/MYSQL/POSTGRESQL等）';
comment on column public.etl_target.connect_config is '连接配置JSON';
comment on column public.etl_target.writer_template_key is 'writer模板键';
comment on column public.etl_target.enabled is '是否启用';
comment on column public.etl_target.is_default is '是否默认目标端';
comment on column public.etl_target.remark is '备注';
comment on column public.etl_table.target_id is '目标端ID，引用etl_target.id';

alter table public.etl_table
  add column if not exists start_at time;

comment on column public.etl_table.start_at is '表级采集定时启动时间点；为空表示继承 etl_source.start_at';

create index if not exists idx_etl_table_start_at_not_null
  on public.etl_table (start_at)
  where start_at is not null;

create table public.etl_column
(
  tid              bigint      not null
    constraint etl_column_tid_fk
      references public.etl_table,
  column_name      varchar(255),
  column_id        integer,
  source_type      varchar(64),
  data_length      integer,
  data_precision   integer,
  data_scale       integer,
  col_comment      varchar(4000),
  target_type      varchar(50) not null,
  target_type_full varchar(100),
  update_at        timestamp default CURRENT_TIMESTAMP
);

comment on table public.etl_column is '采集的表字段信息，包括源表和目标表';

comment on column public.etl_column.tid is '采集表主键 ID，对应 tb_etl_table 中的 tid';

comment on column public.etl_column.column_name is '原表字段名称';

comment on column public.etl_column.column_id is '列 ID，用于排序字段';

comment on column public.etl_column.source_type is '源表的数据类型';

comment on column public.etl_column.data_length is '数据长度';

comment on column public.etl_column.data_precision is '精度';

comment on column public.etl_column.data_scale is '小数位';

comment on column public.etl_column.col_comment is '字段注释';

comment on column public.etl_column.target_type is '目标表对应的类型';

comment on column public.etl_column.target_type_full is '目标表字段的完整类型，比如 decimal(10,3)';

comment on column public.etl_column.update_at is '更新时间';

create unique index uk_tid_column_name
  on public.etl_column (tid, column_name);

create table public.etl_job
(
  tid bigint not null
    constraint pk_tb_job
      primary key
    constraint etl_job_tid_fk
      references public.etl_table,
  job text   not null
);

comment on table public.etl_job is '采集表的 addax 任务模板';

comment on column public.etl_job.tid is '采集表主键';

comment on column public.etl_job.job is 'addax 任务模板';

create table public.etl_jour
(
  id        bigserial
    primary key,
  tid       bigint
    constraint etl_jour_tid_fk
      references public.etl_table,
  kind      varchar(32),
  start_at  timestamp default CURRENT_TIMESTAMP not null,
  duration  integer   default 0                 not null,
  status    boolean   default true,
  cmd       text,
  error_msg text
);


create index idx_etl_jour_tid
  on public.etl_jour (tid);

create index idx_etl_table_status_id_sid
  on public.etl_table (status, id, sid);

create table public.groups
(
  id         bigint generated by default as identity
    primary key,
  group_name varchar(50) not null
);


create table public.group_authorities
(
  group_id  bigint      not null
    constraint fk_group_authorities_group
      references public.groups,
  authority varchar(50) not null
);

create table public.group_members
(
  id       bigint generated by default as identity
    primary key,
  username varchar(50) not null,
  group_id bigint      not null
    constraint fk_group_members_group
      references public.groups
);

create table public.notification
(
  id        bigserial
    primary key,
  phone     varchar(255)                        not null,
  msg       varchar(500)                        not null,
  sms       char      default 'Y'::bpchar       not null,
  im        char      default 'Y'::bpchar       not null,
  call      char      default 'N'::bpchar       not null,
  create_at timestamp default CURRENT_TIMESTAMP not null
);

comment on table public.notification is '数据中心消息提醒总表';

comment on column public.notification.id is '自动生成，无需理会';

comment on column public.notification.phone is '接收人号码或者其他唯一标识，用逗号分隔';

comment on column public.notification.msg is '消息内容';

comment on column public.notification.sms is '是否发送短信，发送成功后置为y';

comment on column public.notification.im is '是否发送企微，发送成功后置为y';

comment on column public.notification.call is '是否拨打语音，拨打成功后置为y';

comment on column public.notification.create_at is '消息生成的时间，自动生成';

create table public.user_notification
(
  id         bigserial
    primary key,
  username   varchar(64)                         not null,
  title      varchar(200)                        not null,
  content    text,
  type       varchar(50),
  status     varchar(16) default 'UNREAD'::character varying not null,
  ref_type   varchar(50),
  ref_id     varchar(64),
  created_at timestamp default CURRENT_TIMESTAMP not null,
  read_at    timestamp
);

create index idx_user_notification_user_status
  on public.user_notification (username, status, created_at);

create table public.schema_change_log
(
  id                 bigserial
    primary key,
  tid                bigint not null,
  source_db          varchar(64),
  source_table       varchar(128),
  column_name        varchar(255),
  change_type        varchar(32),
  old_source_type    varchar(128),
  new_source_type    varchar(128),
  old_data_length    integer,
  new_data_length    integer,
  old_data_precision integer,
  new_data_precision integer,
  old_data_scale     integer,
  new_data_scale     integer,
  old_col_comment    varchar(2000),
  new_col_comment    varchar(2000),
  change_at          timestamp default CURRENT_TIMESTAMP
);

create table public.sys_dict
(
  code           integer not null
    constraint pk_tb_dict
      primary key,
  name           varchar(255),
  classification varchar(2000),
  remark         varchar(500)
);

comment on table public.sys_dict is '字典条目表';

comment on column public.sys_dict.code is '条目编号';

comment on column public.sys_dict.name is '条目名称';

comment on column public.sys_dict.classification is '分类';

comment on column public.sys_dict.remark is '说明';

create table public.sys_item
(
  dict_code  integer      not null
    constraint tb_item_dict_fk
      references public.sys_dict
      on update cascade on delete cascade,
  item_key   varchar(255) not null,
  item_value varchar(2000),
  remark     varchar(4000),
  constraint pk_tb_dictionary
    primary key (dict_code, item_key)
);

comment on table public.sys_item is '字典明细表';

comment on column public.sys_item.dict_code is '字典条目编号';

comment on column public.sys_item.item_key is '明细名称';

comment on column public.sys_item.item_value is '明细内容';

comment on column public.sys_item.remark is '备注';

create table public.system_flag
(
  flag_key         varchar(128) not null
    primary key,
  flag_value       varchar(128) default '0'::character varying,
  last_started_at  timestamp,
  last_finished_at timestamp,
  updated_at       timestamp,
  updated_by       varchar(255)
);

create table public.users
(
  username varchar(50)  not null
    primary key,
  password varchar(500) not null,
  enabled  boolean      not null
);

create table public.authorities
(
  username  varchar(50) not null
    constraint fk_authorities_users
      references public.users,
  authority varchar(50) not null
);

create unique index ix_auth_username
  on public.authorities (username, authority);

create table public.leader_election
(
  id         integer,
  node_id    varchar(100),
  expires_at timestamp with time zone,
  updated_at timestamp with time zone
);

comment on table public.leader_election is 'leader 选举表';

comment on column public.leader_election.node_id is '节点ID';

comment on column public.leader_election.expires_at is '过期时间';

comment on column public.leader_election.updated_at is '更新时间';

create table public.risk_log
(
  id         bigserial,
  risk_level varchar(30) not null,
  source     varchar(30),
  message    varchar(1000),
  tid        integer,
  created_at timestamp default CURRENT_TIMESTAMP
);

comment on table public.risk_log is '风险记录表';

comment on column public.risk_log.risk_level is '风险级别';

comment on column public.risk_log.source is '风险来源';

comment on column public.risk_log.message is '风险摘要';

comment on column public.risk_log.tid is '关联表 ID';

comment on column public.risk_log.created_at is '创建时间';

create view vw_etl_table_with_source
   as
SELECT t.*,
       s.code,
       s.name,
       s.url,
       s.username,
       s.pass,
       s.start_at as source_start_at,
       s.enabled,
       s.max_concurrency,
       s.db_type,
       tt.target_type,
       tt.code as target_code,
       tt.name as target_name,
       tt.enabled as target_enabled
FROM etl_table t
       LEFT JOIN etl_source s ON t.sid = s.id
       LEFT JOIN etl_target tt ON t.target_id = tt.id;


create function insert_dates_for_year(p_year integer, p_dict_code integer DEFAULT 1021) returns void
  language plpgsql
as
$$
DECLARE
  v_date varchar;
BEGIN
  FOR v_date IN
    SELECT DISTINCT to_char(generate_series(make_date(p_year,1,1), make_date(p_year,12,31), '1 day'::interval), 'YYYYmmdd')
    -- SELECT DISTINCT date_trunc('day', generate_series('2025-01-01'::date, '2025-12-31'::date, '1 day'))
    LOOP
      INSERT INTO public.sys_item (dict_code, item_key, item_value, remark)
      VALUES (p_dict_code, v_date, v_date, NOW());
    END LOOP;
END;
$$;
